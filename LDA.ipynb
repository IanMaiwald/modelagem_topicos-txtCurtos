{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ebf7b7-8488-4e35-a75d-62d7b1afff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as libs necessárias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, FastText, Word2Vec\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.matutils import hellinger\n",
    "from gensim.matutils import sparse2full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198ca14e-c177-49bd-8b0c-3ed9c8a2734d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coronavirus aceitar braco abrir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>achar eleitor bolsonaro medo coronavirus febre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fome coronavirus entrar fila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trancar replies twetr sala coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caso coronavirus confirmar Brasil mundo querer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>preciso comando vermelho decretar toque recolh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>urgente reporter confirmar segundo morte coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>informativo elaborar equipe viano azevedo advo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>vivo Paulo confirmar primeiro morte covid19 Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>bolsonaro protesto coronavirus pegar gado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    texto\n",
       "0                         coronavirus aceitar braco abrir\n",
       "1       achar eleitor bolsonaro medo coronavirus febre...\n",
       "2                            fome coronavirus entrar fila\n",
       "3                  trancar replies twetr sala coronavirus\n",
       "4       caso coronavirus confirmar Brasil mundo querer...\n",
       "...                                                   ...\n",
       "99996   preciso comando vermelho decretar toque recolh...\n",
       "99997   urgente reporter confirmar segundo morte coron...\n",
       "99998   informativo elaborar equipe viano azevedo advo...\n",
       "99999   vivo Paulo confirmar primeiro morte covid19 Br...\n",
       "100000          bolsonaro protesto coronavirus pegar gado\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura dos dados do dataframe\n",
    "#df = pd.read_csv('datasets/(processado-final)textos_tuitesPt_2020.csv.gz', names=['texto'])\n",
    "df = pd.read_csv('datasets/(processado)textos_tuitesPt_2020_0.csv', names=['texto'])\n",
    "\n",
    "# Elimina um valor flutuante que aparece no dataframe (por razões misteriosas)\n",
    "# o algoritmo não aceita o valor flutuante, que precisa ser filtrado\n",
    "df = df[df['texto'].apply(lambda x: isinstance(x, str))]\n",
    "df['texto'].apply(type).value_counts()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be3cf4f-f66e-4c40-bcf8-d1c35c397e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair os textos dos documentos\n",
    "docs = df['texto'].tolist()\n",
    "\n",
    "# Tokenização dos documentos\n",
    "docs_tokenizados = [doc.split() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faacf579-dd59-4354-ae19-172dd8c1c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um dicionário a partir dos documentos tokenizados\n",
    "dicionario = corpora.Dictionary(docs_tokenizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac0f434-06f7-4718-8fca-01940fde258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um corpus a partir do dicionário e dos documentos tokenizados\n",
    "corpus = [dicionario.doc2bow(doc) for doc in docs_tokenizados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57e68c9-a9ad-4bec-8dda-bb608796fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo LDA\n",
    "modelo_lda = gensim.models.LdaMulticore(corpus=corpus, id2word=dicionario, num_topics=10, passes=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0571e639-de43-4327-b192-902613b3158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.076*\"coronavirus\" + 0.037*\"bolsonaro\" + 0.027*\"presidente\" + 0.018*\"Brasil\" + 0.014*\"brasileiro\" + 0.013*\"povo\" + 0.012*\"mundo\" + 0.007*\"falar\" + 0.007*\"infectar\" + 0.007*\"manifestacao\" + 0.007*\"dia\" + 0.006*\"rua\" + 0.006*\"governo\" + 0.006*\"fazer\" + 0.006*\"pai\" + 0.006*\"politico\" + 0.006*\"manifestacoes\" + 0.005*\"culpa\" + 0.005*\"congresso\" + 0.005*\"bolsonaroday\"')\n",
      "(1, '0.083*\"coronavirus\" + 0.066*\"caso\" + 0.041*\"covid19\" + 0.029*\"confirmar\" + 0.027*\"Brasil\" + 0.017*\"morte\" + 0.017*\"novo\" + 0.014*\"positivo\" + 0.011*\"numero\" + 0.010*\"primeiro\" + 0.009*\"teste\" + 0.008*\"Portugal\" + 0.008*\"suspeito\" + 0.008*\"italia\" + 0.007*\"saude\" + 0.007*\"dia\" + 0.007*\"Paulo\" + 0.007*\"exame\" + 0.007*\"testar\" + 0.006*\"dois\"')\n",
      "(2, '0.103*\"coronavirus\" + 0.025*\"casa\" + 0.022*\"ficar\" + 0.016*\"sair\" + 0.015*\"chegar\" + 0.013*\"mundo\" + 0.013*\"dia\" + 0.012*\"bom\" + 0.010*\"gente\" + 0.009*\"pegar\" + 0.008*\"pensar\" + 0.007*\"pessoa\" + 0.007*\"acabar\" + 0.007*\"passar\" + 0.007*\"falar\" + 0.006*\"logo\" + 0.006*\"achar\" + 0.006*\"cura\" + 0.006*\"bem\" + 0.005*\"matar\"')\n",
      "(3, '0.068*\"coronavirus\" + 0.018*\"b20\" + 0.017*\"acreditar\" + 0.017*\"demais\" + 0.014*\"covid19\" + 0.013*\"tempo\" + 0.013*\"news\" + 0.011*\"longe\" + 0.011*\"fazer\" + 0.009*\"Fake\" + 0.007*\"certo\" + 0.007*\"suspenso\" + 0.006*\"globo\" + 0.006*\"passar\" + 0.005*\"puta\" + 0.005*\"aulo\" + 0.005*\"Daniel\" + 0.005*\"imbecil\" + 0.005*\"limite\" + 0.004*\"cubano\"')\n",
      "(4, '0.079*\"coronavirus\" + 0.030*\"covid19\" + 0.024*\"causa\" + 0.021*\"cancelar\" + 0.017*\"aula\" + 0.016*\"suspender\" + 0.013*\"dia\" + 0.013*\"fechar\" + 0.009*\"gel\" + 0.009*\"contar\" + 0.009*\"evento\" + 0.009*\"adiar\" + 0.008*\"alcolr\" + 0.008*\"escola\" + 0.007*\"jogo\" + 0.006*\"semana\" + 0.006*\"show\" + 0.005*\"casa\" + 0.005*\"ficar\" + 0.005*\"pessoa\"')\n",
      "(5, '0.063*\"coronavirus\" + 0.024*\"mao\" + 0.010*\"covid19\" + 0.010*\"lavar\" + 0.010*\"tirar\" + 0.009*\"ficar\" + 0.008*\"abrir\" + 0.008*\"meio\" + 0.007*\"achar\" + 0.007*\"dinheiro\" + 0.007*\"gente\" + 0.006*\"brincadeira\" + 0.006*\"crise\" + 0.006*\"dolar\" + 0.006*\"parecer\" + 0.006*\"pegar\" + 0.005*\"tocar\" + 0.005*\"prender\" + 0.005*\"irresponsavel\" + 0.005*\"quarentena\"')\n",
      "(6, '0.052*\"covid19\" + 0.039*\"coronavirus\" + 0.014*\"pandemia\" + 0.010*\"saude\" + 0.010*\"governo\" + 0.009*\"China\" + 0.008*\"novo\" + 0.007*\"publico\" + 0.007*\"medida\" + 0.007*\"situacao\" + 0.006*\"pessoa\" + 0.006*\"social\" + 0.005*\"oms\" + 0.005*\"mundo\" + 0.005*\"italia\" + 0.005*\"anunciar\" + 0.005*\"noticio\" + 0.005*\"Brasil\" + 0.005*\"criar\" + 0.005*\"fronteira\"')\n",
      "(7, '0.051*\"Virus\" + 0.040*\"corona\" + 0.037*\"virus\" + 0.031*\"coronar\" + 0.031*\"covid19\" + 0.029*\"coronavirus\" + 0.020*\"matar\" + 0.011*\"ano\" + 0.010*\"gostar\" + 0.009*\"atencao\" + 0.008*\"existir\" + 0.008*\"pneumonia\" + 0.007*\"gripe\" + 0.007*\"idoso\" + 0.007*\"pessoa\" + 0.005*\"Gripe\" + 0.005*\"saber\" + 0.004*\"doenca\" + 0.004*\"senhor\" + 0.004*\"vir\"')\n",
      "(8, '0.095*\"coronavirus\" + 0.023*\"falar\" + 0.022*\"pegar\" + 0.020*\"gente\" + 0.014*\"medo\" + 0.013*\"morrer\" + 0.013*\"nao\" + 0.012*\"deus\" + 0.011*\"achar\" + 0.010*\"porra\" + 0.009*\"olhar\" + 0.008*\"mano\" + 0.008*\"cara\" + 0.008*\"serio\" + 0.008*\"pessoa\" + 0.008*\"caralho\" + 0.007*\"ficar\" + 0.007*\"mae\" + 0.006*\"Deus\" + 0.006*\"passar\"')\n",
      "(9, '0.045*\"coronavirus\" + 0.041*\"covid19\" + 0.013*\"saude\" + 0.011*\"risco\" + 0.011*\"medida\" + 0.011*\"pessoa\" + 0.009*\"evitar\" + 0.008*\"tomar\" + 0.008*\"saber\" + 0.007*\"prevencao\" + 0.007*\"precisar\" + 0.007*\"bom\" + 0.007*\"medico\" + 0.006*\"grupo\" + 0.005*\"ajudar\" + 0.005*\"virus\" + 0.005*\"cuidado\" + 0.004*\"tempo\" + 0.004*\"governo\" + 0.004*\"sintoma\"')\n"
     ]
    }
   ],
   "source": [
    "# Imprimir os tópicos do modelo\n",
    "for topico in modelo_lda.print_topics(num_words=20):\n",
    "    print(topico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b1fb38-f1e0-4ecd-a107-0a8d71229649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A perplexidade do modelo LDA é -8.582428976491816\n"
     ]
    }
   ],
   "source": [
    "perplexidade = modelo_lda.log_perplexity(corpus)\n",
    "\n",
    "print(f\"A perplexidade do modelo LDA é {perplexidade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d815e054-e14a-4987-b2bc-d9a664f0c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a distância de tópicos\n",
    "distance_matrix = similarities.MatrixSimilarity([modelo_lda.get_topic_terms(topicid) for topicid in range(modelo_lda.num_topics)])\n",
    "hellinger_distance_matrix = distance_matrix.index\n",
    "for i in range(modelo_lda.num_topics):\n",
    "    for j in range(i+1, modelo_lda.num_topics):\n",
    "        hellinger_distance_matrix[i][j] = hellinger(modelo_lda.get_topic_terms(i), modelo_lda.get_topic_terms(j))\n",
    "\n",
    "# Imprimir a matriz de distância\n",
    "print(hellinger_distance_matrix)\n",
    "\n",
    "# Calcular a mediana da matriz de distância de Hellinger\n",
    "median_distance = np.median(hellinger_distance_matrix)\n",
    "\n",
    "print(f\"A distância de tópicos média é {median_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877bac82-5988-4fe6-b6a8-039b5ee17302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as distribuições de palavras para cada tópico\n",
    "topic_word_dists = modelo_lda.get_topics()\n",
    "\n",
    "# Calcular a divergência KL-simétrica entre todos os pares de tópicos\n",
    "num_topics = modelo_lda.num_topics\n",
    "kl_divergence_matrix = np.zeros((num_topics, num_topics))\n",
    "for i in range(num_topics):\n",
    "    for j in range(i+1, num_topics):\n",
    "        kl_divergence = 0.5 * (hellinger(sparse2full(modelo_lda.get_topic_terms(i), len(dicionario)), topic_word_dists[j]) +\n",
    "                               hellinger(sparse2full(modelo_lda.get_topic_terms(j), len(dicionario)), topic_word_dists[i]))\n",
    "        kl_divergence_matrix[i][j] = kl_divergence\n",
    "        kl_divergence_matrix[j][i] = kl_divergence\n",
    "\n",
    "# Imprimir a matriz de divergência KL-simétrica\n",
    "print(kl_divergence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29da43a8-79a3-43f4-b7f3-8cadea6a8c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A divergência KL média dos tópicos é 0.7109533816603362\n"
     ]
    }
   ],
   "source": [
    "# Calcular a mediana da matriz de distância de Hellinger\n",
    "median_kl_divergence = np.median(kl_divergence_matrix)\n",
    "\n",
    "print(f\"A divergência KL média dos tópicos é {median_kl_divergence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a35e595b-7e19-42f2-8f23-873854d71e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coerência C_umass dos tópicos é -4.465550991903749\n"
     ]
    }
   ],
   "source": [
    "# Calcular a medida de coerência C_umass\n",
    "coherence_model = CoherenceModel(model=modelo_lda, texts=docs_tokenizados, dictionary=dicionario, coherence='u_mass')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "# Imprimir a medida de coerência C_umass\n",
    "print('A coerência C_umass dos tópicos é', coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6f0face-b18a-4acd-9bfe-1c4671a0e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coerência C_w2v dos tópicos é 0.73445296\n"
     ]
    }
   ],
   "source": [
    "# Calcular a medida de coerência C_w2v\n",
    "coherence_model = CoherenceModel(model=modelo_lda, texts=docs_tokenizados, dictionary=dicionario, coherence='c_w2v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "# Imprimir a medida de coerência C_w2v\n",
    "print('A coerência C_w2v dos tópicos é',coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13dcd32-50b2-4565-a1ca-04d1ea2371b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
