{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4c1182-c73f-43c9-8b3f-6ccd904f0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23dd74b-ff63-4286-a26a-795ed6d4dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(data, n_topics, n_terms, n_meta_features):\n",
    "    theta = np.random.dirichlet(alpha=np.ones(n_topics), size=data.shape[0])\n",
    "    beta = np.random.dirichlet(alpha=np.ones(n_terms), size=n_topics)\n",
    "    gamma = np.random.dirichlet(alpha=np.ones(n_meta_features), size=n_topics)\n",
    "    return theta, beta, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685700dc-7cd7-4ce4-841a-48c965e9cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(data, theta, beta, gamma, meta_info):\n",
    "    phi = np.zeros((data.shape[0], beta.shape[0]))\n",
    "\n",
    "    for d in range(data.shape[0]):\n",
    "        for k in range(beta.shape[0]):\n",
    "            phi[d, k] = theta[d, k] * np.prod(np.power(beta[k, :], data[d, :])) * np.prod(np.power(gamma[k, :], meta_info[d, :]))\n",
    "        phi[d, :] /= np.sum(phi[d, :])\n",
    "\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c6a300-222c-47a6-8bf8-f12c35cc64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(data, phi, theta, beta, gamma, meta_info):\n",
    "    for d in range(data.shape[0]):\n",
    "        theta[d, :] = (phi[d, :] + 1) / (np.sum(phi[d, :]) + beta.shape[0])\n",
    "\n",
    "    for k in range(beta.shape[0]):\n",
    "        for w in range(beta.shape[1]):\n",
    "            beta[k, w] = np.sum(data[:, w] * phi[:, k]) / np.sum(data * phi)\n",
    "\n",
    "        for m in range(gamma.shape[1]):\n",
    "            gamma[k, m] = np.sum(meta_info[:, m] * phi[:, k]) / np.sum(meta_info * phi)\n",
    "\n",
    "    return theta, beta, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c0180a-0027-41d0-99fe-628d807a3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIGA(data, meta_info, n_topics, max_iter=100, tol=1e-6):\n",
    "    n_terms = data.shape[1]\n",
    "    n_meta_features = meta_info.shape[1]\n",
    "\n",
    "    theta, beta, gamma = initialize_parameters(data, n_topics, n_terms, n_meta_features)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        theta_prev = theta.copy()\n",
    "\n",
    "        phi = E_step(data, theta, beta, gamma, meta_info)\n",
    "        theta, beta, gamma = M_step(data, phi, theta, beta, gamma, meta_info)\n",
    "\n",
    "        if np.mean(np.abs(theta - theta_prev)) < tol:\n",
    "            break\n",
    "\n",
    "    return theta, beta, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85225671-4fea-473d-9c16-6f407882ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(beta, vocab, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(beta):\n",
    "        top_words = [vocab[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        print(f\"Topic #{topic_idx + 1}: {', '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c21e78-b9a5-49dd-95a0-3d74237e3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados do dataframe\n",
    "#df = pd.read_csv('datasets/(processado-final)textos_tuitesPt_2020.csv.gz', names=['texto'])\n",
    "df = pd.read_csv('datasets/(processado)textos_tuitesPt_2020_0.csv', names=['texto'])\n",
    "\n",
    "# Elimina um valor flutuante que aparece no dataframe (por razões misteriosas)\n",
    "# o algoritmo não aceita o valor flutuante, que precisa ser filtrado\n",
    "df = df[df['texto'].apply(lambda x: isinstance(x, str))]\n",
    "df['texto'].apply(type).value_counts()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f344f-3a1a-49ed-902a-5c63593f1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para matrizes NumPy\n",
    "data_np = df['texto'].to_numpy()\n",
    "meta_info_np = meta_info.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2daac91-a0ec-464f-b4b8-1e2ad7f78601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar o algoritmo MIGA\n",
    "n_topics = 10\n",
    "theta, beta, gamma = MIGA(data_np, meta_info_np, n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dffd78-ba46-47a3-8ff2-4ab2764b07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "data_transformed = vectorizer.fit_transform(data)\n",
    "\n",
    "vocab = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc01e1-b36c-4d10-9621-9a763003bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os tópicos e as principais palavras\n",
    "n_top_words = 10\n",
    "display_topics(beta, vocab, n_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
