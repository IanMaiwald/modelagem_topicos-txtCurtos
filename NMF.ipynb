{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066fe670-48e2-44c5-b16d-cbb4e31adcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984dde3c-8ccb-4bdc-8540-6bf241f54448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coronavirus aceitar braco abrir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>achar eleitor bolsonaro medo coronavirus febre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fome coronavirus entrar fila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trancar replies twetr sala coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caso coronavirus confirmar Brasil mundo querer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>preciso acalmar puertorico boardgame jogosdeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>assustar aparentemente virus covid vez agir vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>bem bom perder milhar vida covid19 fiquemcasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>testir saber infectar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500000</th>\n",
       "      <td>comando conjunto sul continuar campanha doacao...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    texto\n",
       "0                         coronavirus aceitar braco abrir\n",
       "1       achar eleitor bolsonaro medo coronavirus febre...\n",
       "2                            fome coronavirus entrar fila\n",
       "3                  trancar replies twetr sala coronavirus\n",
       "4       caso coronavirus confirmar Brasil mundo querer...\n",
       "...                                                   ...\n",
       "499996  preciso acalmar puertorico boardgame jogosdeta...\n",
       "499997  assustar aparentemente virus covid vez agir vi...\n",
       "499998      bem bom perder milhar vida covid19 fiquemcasa\n",
       "499999                              testir saber infectar\n",
       "500000  comando conjunto sul continuar campanha doacao...\n",
       "\n",
       "[500000 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura dos dados do dataframe\n",
    "df = pd.read_csv('datasets/(processado-final)textos_tuitesPt_2020.csv.gz', names=['texto'])\n",
    "\n",
    "# Elimina um valor flutuante que aparece no dataframe (por razões misteriosas)\n",
    "# o algoritmo não aceita o valor flutuante, que precisa ser filtrado\n",
    "df = df[df['texto'].apply(lambda x: isinstance(x, str))]\n",
    "df['texto'].apply(type).value_counts()\n",
    "\n",
    "df = df.head(500000)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d6a6ba-8318-403c-8926-d854e67b295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de tópicos desejados\n",
    "n_components = 10\n",
    "\n",
    "# Cria o objeto TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words=None)\n",
    "\n",
    "# Cria a matriz de termo-documento\n",
    "X = vectorizer.fit_transform(df['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7af262-cf59-4317-aad8-f77cb384562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa o NMF\n",
    "nmf = NMF(n_components=n_components, init='nndsvd', random_state=1)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c07d5a4-84c9-419c-bd9f-4610853b5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém os tópicos para o primeiro documento\n",
    "doc = df['texto'][0]\n",
    "tfidf_doc = vectorizer.transform([doc])\n",
    "topic_scores = tfidf_doc.dot(H.T)\n",
    "topic_indices = topic_scores.argsort()[::-1][:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17d0d75-836a-44e0-9fbe-20e983395ca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5612/3075465713.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Obtém as palavras correspondentes a cada coluna da matriz de frequência de termos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Imprime as palavras correspondentes a cada tópico\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Palavras e pesos dos tópicos:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "# Obtém as palavras correspondentes a cada coluna da matriz de frequência de termos\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Imprime as palavras correspondentes a cada tópico\n",
    "print(\"Palavras e pesos dos tópicos:\")\n",
    "for i, topic in enumerate(H):\n",
    "    top_words_indices = topic.argsort()[:-11:-1]\n",
    "    topic_words = [feature_names[j] for j in top_words_indices]\n",
    "    topic_weights = topic[top_words_indices]\n",
    "    print(\"Tópico {}: {}\".format(i, [(word, weight) for word, weight in zip(topic_words, topic_weights)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3b682-bdf3-4c89-8235-53ec48b2bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a perplexidade do modelo\n",
    "term_frequency = X.sum(axis=1)\n",
    "term_probability = np.array(term_frequency / term_frequency.sum())\n",
    "doc_topic_probability = W / W.sum(axis=1).reshape(-1, 1)\n",
    "topic_word_probability = H / H.sum(axis=1).reshape(-1, 1)\n",
    "perplexity = np.exp(-np.sum(term_probability * np.log(doc_topic_probability @ topic_word_probability)))\n",
    "print(\"Perplexidade do modelo: {:.2f}\".format(perplexity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
