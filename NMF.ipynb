{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066fe670-48e2-44c5-b16d-cbb4e31adcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984dde3c-8ccb-4bdc-8540-6bf241f54448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados do dataframe\n",
    "df = pd.read_csv('datasets/(processado-final)textos_tuitesPt_2020.csv.gz', names=['texto'])\n",
    "\n",
    "# Elimina um valor flutuante que aparece no dataframe (por razões misteriosas)\n",
    "# o algoritmo não aceita o valor flutuante, que precisa ser filtrado\n",
    "df = df[df['texto'].apply(lambda x: isinstance(x, str))]\n",
    "df['texto'].apply(type).value_counts()\n",
    "\n",
    "df = df.head(500000)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d6a6ba-8318-403c-8926-d854e67b295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de tópicos desejados\n",
    "n_components = 10\n",
    "\n",
    "# Cria o objeto TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words=None)\n",
    "\n",
    "# Cria a matriz de termo-documento\n",
    "X = vectorizer.fit_transform(df['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7af262-cf59-4317-aad8-f77cb384562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa o NMF\n",
    "nmf = NMF(n_components=n_components, init='nndsvd', random_state=1)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c07d5a4-84c9-419c-bd9f-4610853b5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém os tópicos para o primeiro documento\n",
    "doc = df['texto'][0]\n",
    "tfidf_doc = vectorizer.transform([doc])\n",
    "topic_scores = tfidf_doc.dot(H.T)\n",
    "topic_indices = topic_scores.argsort()[::-1][:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d0d75-836a-44e0-9fbe-20e983395ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém as palavras correspondentes a cada coluna da matriz de frequência de termos\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Imprime as palavras correspondentes a cada tópico\n",
    "print(\"Palavras e pesos dos tópicos:\")\n",
    "for i, topic in enumerate(H):\n",
    "    top_words_indices = topic.argsort()[:-11:-1]\n",
    "    topic_words = [feature_names[j] for j in top_words_indices]\n",
    "    topic_weights = topic[top_words_indices]\n",
    "    print(\"Tópico {}: {}\".format(i, [(word, weight) for word, weight in zip(topic_words, topic_weights)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3b682-bdf3-4c89-8235-53ec48b2bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a perplexidade do modelo\n",
    "term_frequency = X.sum(axis=1)\n",
    "term_probability = np.array(term_frequency / term_frequency.sum())\n",
    "doc_topic_probability = W / W.sum(axis=1).reshape(-1, 1)\n",
    "topic_word_probability = H / H.sum(axis=1).reshape(-1, 1)\n",
    "perplexity = np.exp(-np.sum(term_probability * np.log(doc_topic_probability @ topic_word_probability)))\n",
    "print(\"Perplexidade do modelo: {:.2f}\".format(perplexity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
