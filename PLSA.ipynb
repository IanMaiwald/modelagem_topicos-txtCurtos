{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663376a9-3ef0-4713-a1af-867cc318925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d735c93-33d6-44af-b752-e03cc2acc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLSA:\n",
    "    def __init__(self, n_topics, n_iterations=100, tol=1e-4, n_workers=None):\n",
    "        self.n_topics = n_topics\n",
    "        self.n_iterations = n_iterations\n",
    "        self.tol = tol\n",
    "        self.n_workers = n_workers\n",
    "\n",
    "    def initialize(self, term_document_matrix):\n",
    "        n_terms, n_docs = term_document_matrix.shape\n",
    "\n",
    "        self.prob_term_topic = np.random.rand(n_terms, self.n_topics)\n",
    "        self.prob_doc_topic = np.random.rand(n_docs, self.n_topics)\n",
    "        self.prob_topic = np.random.rand(self.n_topics)\n",
    "\n",
    "        self.prob_term_topic /= np.sum(self.prob_term_topic, axis=0)\n",
    "        self.prob_doc_topic /= np.sum(self.prob_doc_topic, axis=1)[:, np.newaxis]\n",
    "        self.prob_topic /= np.sum(self.prob_topic)\n",
    "\n",
    "    def e_step(self, term_document_matrix):\n",
    "        n_terms, n_docs = term_document_matrix.shape\n",
    "        prob_term_doc_topic = np.zeros((n_terms, n_docs, self.n_topics))\n",
    "\n",
    "        def process_term(i):\n",
    "            for j in range(n_docs):\n",
    "                for k in range(self.n_topics):\n",
    "                    prob_term_doc_topic[i, j, k] = self.prob_term_topic[i, k] * self.prob_doc_topic[j, k] * self.prob_topic[k]\n",
    "                prob_term_doc_topic[i, j, :] /= np.sum(prob_term_doc_topic[i, j, :])\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_workers) as executor:\n",
    "            executor.map(process_term, range(n_terms))\n",
    "\n",
    "        return prob_term_doc_topic\n",
    "\n",
    "    def m_step(self, term_document_matrix, prob_term_doc_topic):\n",
    "        self.prob_term_topic = np.sum(term_document_matrix.toarray()[:, :, np.newaxis] * prob_term_doc_topic.toarray(), axis=1)\n",
    "        self.prob_term_topic /= np.sum(self.prob_term_topic, axis=0)\n",
    "\n",
    "        self.prob_doc_topic = np.sum(term_document_matrix.toarray()[:, :, np.newaxis] * prob_term_doc_topic.toarray(), axis=0)\n",
    "        self.prob_doc_topic /= np.sum(self.prob_doc_topic, axis=1)[:, np.newaxis]\n",
    "\n",
    "        self.prob_topic = np.sum(np.sum(term_document_matrix.toarray()[:, :, np.newaxis] * prob_term_doc_topic.toarray(), axis=0), axis=0)\n",
    "        self.prob_topic /= np.sum(self.prob_topic)\n",
    "\n",
    "    def log_likelihood(self, term_document_matrix):\n",
    "        ll = 0\n",
    "        for i in range(term_document_matrix.shape[0]):\n",
    "            for j in range(term_document_matrix.shape[1]):\n",
    "                ll += term_document_matrix[i, j] * np.log(np.sum(self.prob_term_topic[i, :] * self.prob_doc_topic[j, :] * self.prob_topic))\n",
    "\n",
    "        return ll\n",
    "\n",
    "    def fit(self, term_document_matrix):\n",
    "        self.initialize(term_document_matrix)\n",
    "\n",
    "        # Converter a matriz de termos-documentos em uma matriz densa (NumPy array)\n",
    "        term_document_matrix_dense = term_document_matrix.toarray()\n",
    "\n",
    "        prev_ll = -np.inf\n",
    "        for iteration in range(self.n_iterations):\n",
    "            prob_term_doc_topic = self.e_step(term_document_matrix_dense)\n",
    "            self.m_step(term_document_matrix_dense, prob_term_doc_topic)\n",
    "\n",
    "            ll = self.log_likelihood(term_document_matrix_dense)\n",
    "            if np.abs(ll - prev_ll) < self.tol:\n",
    "                break\n",
    "\n",
    "            prev_ll = ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41469ad0-f201-4001-9037-066dfd986e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coronavirus aceitar braco abrir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>achar eleitor bolsonaro medo coronavirus febre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fome coronavirus entrar fila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trancar replies twetr sala coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caso coronavirus confirmar Brasil mundo querer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>preciso comando vermelho decretar toque recolh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>urgente reporter confirmar segundo morte coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>informativo elaborar equipe viano azevedo advo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>vivo Paulo confirmar primeiro morte covid19 Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>bolsonaro protesto coronavirus pegar gado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    texto\n",
       "0                         coronavirus aceitar braco abrir\n",
       "1       achar eleitor bolsonaro medo coronavirus febre...\n",
       "2                            fome coronavirus entrar fila\n",
       "3                  trancar replies twetr sala coronavirus\n",
       "4       caso coronavirus confirmar Brasil mundo querer...\n",
       "...                                                   ...\n",
       "99996   preciso comando vermelho decretar toque recolh...\n",
       "99997   urgente reporter confirmar segundo morte coron...\n",
       "99998   informativo elaborar equipe viano azevedo advo...\n",
       "99999   vivo Paulo confirmar primeiro morte covid19 Br...\n",
       "100000          bolsonaro protesto coronavirus pegar gado\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura dos dados do dataframe\n",
    "#df = pd.read_csv('datasets/(processado-final)textos_tuitesPt_2020.csv.gz', names=['texto'])\n",
    "df = pd.read_csv('datasets/(processado)textos_tuitesPt_2020_0.csv', names=['texto'])\n",
    "\n",
    "# Elimina um valor flutuante que aparece no dataframe (por razões misteriosas)\n",
    "# o algoritmo não aceita o valor flutuante, que precisa ser filtrado\n",
    "df = df[df['texto'].apply(lambda x: isinstance(x, str))]\n",
    "df['texto'].apply(type).value_counts()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3439d86-daab-4465-8cce-7f6d09a1f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"O gato correu atrás do rato\",\n",
    "    \"O rato comeu o queijo\",\n",
    "    \"O cachorro latiu para o gato\",\n",
    "    \"O gato comeu o peixe\",\n",
    "    \"O rato e o gato brincaram juntos\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d026b22a-e522-4526-b149-96cabee62ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma matriz de termos-documentos usando CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "term_document_matrix = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74645228-376f-4d7a-b0e5-7776163ccc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a matriz para o formato CSR (Compressed Sparse Row) para otimização\n",
    "term_document_matrix = sp.csr_matrix(term_document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3f9a25-4494-4395-a5e9-466a3d445018",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18928/1045534540.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplsa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLSA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_document_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18928/4164104794.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, term_document_matrix)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mprob_term_doc_topic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_document_matrix_dense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_document_matrix_dense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_term_doc_topic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_document_matrix_dense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18928/4164104794.py\u001b[0m in \u001b[0;36mm_step\u001b[1;34m(self, term_document_matrix, prob_term_doc_topic)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mm_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_document_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_term_doc_topic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_term_topic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm_document_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprob_term_doc_topic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_term_topic\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_term_topic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "# Instanciar e treinar o modelo PLSA\n",
    "n_topics = 10\n",
    "plsa = PLSA(n_topics)\n",
    "plsa.fit(term_document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80e4fe-aca0-4d95-8dbc-a001dd9a4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar as probabilidades termo-tópico\n",
    "term_topic_matrix = plsa.prob_term_topic\n",
    "for term_index, term in enumerate(vectorizer.get_feature_names()):\n",
    "    print(f\"{term}: {term_topic_matrix[term_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8c86e-d08f-4fc5-87b2-d2cf97659fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar as probabilidades documento-tópico\n",
    "doc_topic_matrix = plsa.prob_doc_topic\n",
    "for doc_index, doc in enumerate(documents):\n",
    "    print(f\"Documento {doc_index}: {doc_topic_matrix[doc_index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
