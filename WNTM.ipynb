{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8152f499-c705-4366-afe7-e40d90fcb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923b008-d5bb-4329-889c-7a5184e916fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados do dataframe\n",
    "#df = pd.read_csv('datasets/(processado-final)textos_tuitesPt_2020.csv.gz', names=['texto'])\n",
    "df = pd.read_csv('datasets/(processado)textos_tuitesPt_2020_0.csv', names=['texto'])\n",
    "\n",
    "# Elimina um valor flutuante que aparece no dataframe (por razões misteriosas)\n",
    "# o algoritmo não aceita o valor flutuante, que precisa ser filtrado\n",
    "df = df[df['texto'].apply(lambda x: isinstance(x, str))]\n",
    "df['texto'].apply(type).value_counts()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464a4f8b-2519-4188-95e0-dd6acb52d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac068557-9998-4851-a7e9-37f9fe12f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(X):\n",
    "    X[X > 0] = 1\n",
    "    return np.dot(X.T, X)\n",
    "\n",
    "co_matrix = co_occurrence_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa2579-626d-4ec6-afe5-02f655dc2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_network(co_matrix, labels, threshold=0):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(labels)\n",
    "    \n",
    "    for i, label1 in enumerate(labels):\n",
    "        for j, label2 in enumerate(labels):\n",
    "            weight = co_matrix[i, j]\n",
    "            if weight > threshold:\n",
    "                G.add_edge(label1, label2, weight=weight)\n",
    "    \n",
    "    return G\n",
    "\n",
    "word_graph = word_network(co_matrix, vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870043a8-c803-4d65-a1d6-8abb893fc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_centrality = nx.eigenvector_centrality(word_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb68d8-fc6f-4cba-bd89-b4443fb8c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_clusters(eigenvector_centrality, n_topics):\n",
    "    sorted_words = sorted(eigenvector_centrality, key=eigenvector_centrality.get, reverse=True)\n",
    "    word_clusters = []\n",
    "    \n",
    "    for i in range(n_topics):\n",
    "        word_clusters.append([])\n",
    "    \n",
    "    for i, word in enumerate(sorted_words):\n",
    "        word_clusters[i % n_topics].append(word)\n",
    "    \n",
    "    return word_clusters\n",
    "\n",
    "n_topics = 5\n",
    "topics = word_clusters(eigenvector_centrality, n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9b059-2622-4666-9019-e783c46ac98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topics(df, topics, eigenvector_centrality):\n",
    "    topic_assignments = []\n",
    "    \n",
    "    for text in df['text']:\n",
    "        topic_scores = np.zeros(len(topics))\n",
    "        \n",
    "        for i, topic in enumerate(topics):\n",
    "            for word in text.split():\n",
    "                if word in topic:\n",
    "                    topic_scores[i] += eigenvector_centrality[word]\n",
    "        \n",
    "        assigned_topic = np.argmax(topic_scores)\n",
    "        topic_assignments.append(assigned_topic)\n",
    "    \n",
    "    return topic_assignments\n",
    "\n",
    "df['topic'] = assign_topics(df, topics, eigenvector_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e53160-09a1-4056-8b38-55145c263e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(topics):\n",
    "    for i, topic in enumerate(topics):\n",
    "        print(f\"Tópico {i + 1}:\")\n",
    "        print(\", \".join(topic))\n",
    "        print()\n",
    "\n",
    "display_topics(topics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
